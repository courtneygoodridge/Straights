# chooseCRANmirror(graphics=FALSE, ind=1) # uncomment for knitting
# rm(list = ls()) # clear workspace
knitr::opts_chunk$set(echo = TRUE)
install.packages(ggplot2)
install.packages(dplyr)
install.packages(tidyr)
install.packages(TTR)
install.packages(zoo)
# install.packages(matlabr)
# install.packages("magrittr")
setwd("M:/PhD/Project/Experiment_Code/Straights") # set working directory
# setwd("C:/Users/Courtney/Documents/PhD/Project/Experiment_code/Straights")
temp = list.files(pattern = c("BenLui17", "*.csv")) # list all CSV files in the directory
myfiles = lapply(temp, read.csv) # read these CSV in the directory
workingdata <- do.call(rbind.data.frame, myfiles) # convert and combine the CSV files into dataframe
library(dplyr)
library(tidyr)
library(TTR)
library(hemm)
library(searcher)
init_hemm()
# change in steering
magnitudethreshold = 0.140
upperthreshold = 0.105 # 0.2184 # upper threshold for consistent steering response
lowerthreshold = 0.02 # 0.005 # lower threshold for when response initiated
workingdata <- unite(workingdata, ppid_trialn, ppid, trialn, sep = "_") # create unique ppid_trialn ID
workingdata <- workingdata %>%
mutate(YawRateChange = YawRate_seconds - c(0, YawRate_seconds[-length(YawRate_seconds)])) %>% #difference in yaw rate
group_by(ppid_trialn) %>%
mutate(frame = row_number()) %>%
ungroup()
workingdata$YawRateChange[workingdata$YawRateChange >= 0.73499999] <- 0 # removes random spikes
colnames(workingdata)[colnames(workingdata)=="SWA"] <- "SWV"
workingdata <- workingdata %>%
mutate(SWA = SWV * 90)
# rows <- workingdata %>%
#   group_by(ppid_trialn) %>%
#   summarise(rows = n())
#
# View(rows)
library(dplyr)
workingdatatimecourseUnsmooth <- workingdata %>%
group_by(ppid_trialn) %>%
mutate(anchored_timestamp = timestamp - min(timestamp)) %>%
filter(anchored_timestamp<=min(anchored_timestamp)+4) %>%
ungroup() # create anchored timestamp and then only select first 4 seconds of data for each each ppid_trialn (only interested in the first steering adjustment as this point)
library(zoo)
library(dplyr)
library(tidyr)
library(TTR)
# implement anchored_timestamp again in code below to search only in first 1.5 seconds. Then use code above to calculate max peak thresholds and whether they pass the filter
# TRUERESPONSE <- workingdatatimecourseUnsmooth %>%
#   group_by(ppid_trialn) %>%
#   mutate(maxValue = max(abs(YawRateChange))) %>%
#   filter(maxValue >= 0.15) %>%
#   mutate(GenuineResponse = TRUE)
#
# FALSERESPONSE <- workingdatatimecourseUnsmooth %>%
#   group_by(ppid_trialn) %>%
#   mutate(maxValue = max(abs(YawRateChange))) %>%
#   filter(maxValue < 0.15) %>%
#   mutate(GenuineResponse = FALSE)
#
# workingdatatimecourseUnsmooth <- rbind(TRUERESPONSE, FALSERESPONSE)
workingdatatimecourseUnsmooth <- workingdatatimecourseUnsmooth %>%
group_by(ppid_trialn) %>%
mutate(PeakMagnitude = max(abs(YawRateChange))) %>% # calculate peak yaw rate change for each trial
ungroup()
workingdatathresholdUnsmooth <- workingdatatimecourseUnsmooth %>%
group_by(ppid_trialn) %>%
mutate(row_number(), Genuine_Response = if_else(PeakMagnitude >= magnitudethreshold, TRUE, FALSE)) %>%
filter(max(abs(YawRateChange)) > upperthreshold, min(abs(YawRateChange)) < lowerthreshold) %>% # filter lowest yaw rate change smaller than the lower theshold, # filter largest yaw rate change greater than the upper threshold
slice(1:min(which(abs(YawRateChange) > upperthreshold, 1))) %>%
slice(max(which(abs(YawRateChange) < lowerthreshold, 1))) %>% # which() returns rows where a condition is true. Taking the min() of all the rows that are greater than the criteria will return the first row where that is true.
ungroup() %>%
transmute(ppid_trialn, heading, cameraoffset, SWAThres = SWA, FirstSteeringTime = anchored_timestamp, ThresWorld_x = World_x, ThresWorld_z = World_z, ThresWorldYaw = WorldYaw, ThresYawRate_seconds = YawRate_seconds, ThresYawRateChange = YawRateChange, Genuine_Response = Genuine_Response, PeakMagnitude = PeakMagnitude) #, maxValue = maxValue, GenuineResponse = GenuineResponse)
workingdatathresholdUnsmooth <- workingdatathresholdUnsmooth %>%
group_by(heading) %>%
mutate(LateResponse = abs(FirstSteeringTime - mean(FirstSteeringTime)) > sd(FirstSteeringTime) & abs(FirstSteeringTime - mean(FirstSteeringTime)) > -sd(FirstSteeringTime))
# returns TRUE if response is more than 1 SD above or below mean first steering time
# guards against too fast/low responses
# returns TRUE if response is more than 1 SD from zero -> mutate(ResponseTooLate = if_else(FirstSteeringTime > 2*sd(FirstSteeringTime), TRUE, FALSE)) # label late responses
##################################### SMOOTHING DATA ###################################
workingdatatimecourseSmooth <- workingdatatimecourseUnsmooth %>%
mutate(smoothedYawRateChange = SMA(YawRateChange, n = 3)) # calculates moving average over the number of data points you specify
workingdatatimecourseSmooth[is.na(workingdatatimecourseSmooth)] <- 0 # set NA values to 0. This is because smoothing data in this way creates NA values if you don't have enough to average over. Unsure how else to get around this
# determine first time in each ppid, trialn group above threshold
workingdatathresholdSmooth <- workingdatatimecourseSmooth %>%
group_by(ppid_trialn) %>%
mutate(row_number(), Genuine_Response = if_else(PeakMagnitude >= magnitudethreshold, TRUE, FALSE)) %>%
filter(max(abs(smoothedYawRateChange)) > upperthreshold, # filter largest yaw rate change greater than the upper threshold
min(abs(smoothedYawRateChange)) < lowerthreshold) %>% # filter lowest yaw rate change smaller than the lower theshold
slice(1:min(which(abs(smoothedYawRateChange) > upperthreshold, 1))) %>%
slice(max(which(abs(smoothedYawRateChange) < lowerthreshold, 1))) %>% # which() returns rows where a condition is true. Taking the min() of all the rows that are greater than the criteria will return the first row where that is true.
ungroup() %>%
transmute(ppid_trialn, heading, cameraoffset, SWAThres = SWA, FirstSteeringTime = anchored_timestamp, ThresWorld_x = World_x, ThresWorld_z = World_z, ThresWorldYaw = WorldYaw, ThresYawRate_seconds = YawRate_seconds, ThresYawRateChange = smoothedYawRateChange, Genuine_Response = Genuine_Response, PeakMagnitude = PeakMagnitude)
workingdatathresholdSmooth <- workingdatathresholdSmooth %>%
group_by(heading) %>%
mutate(LateResponse = abs(FirstSteeringTime - mean(FirstSteeringTime)) > sd(FirstSteeringTime) & abs(FirstSteeringTime - mean(FirstSteeringTime)) > - sd(FirstSteeringTime))
# returns TRUE if response is more than 1 SD above or below mean first steering time
# guards against too fast/low responses
# returns TRUE if response is more than 1 SD from zero -> mutate(ResponseTooLate = if_else(FirstSteeringTime > 2*sd(FirstSteeringTime), TRUE, FALSE)) # label late responses
##################################### SMOOTHING DATA ###################################
# Here SWA angle is redundent as it only takes the SWA for when the change in yaw rate is over the threshold... I'm interested in ThresYawRateChange (first change in yaw rate over threhsold) and FirstYawRateChangeTimeThres (first timestamp where yaw rate change is over threshold).
#Only thing extra would be to calculate frame rate (60 frames) (ask Richard), and then multiply by change in yaw rate to get yaw rate per second per second.
workingdatatimecourseUnsmooth %>%
group_by(ppid_trialn) %>%
a
workingdatatimecourseUnsmooth %>%
group_by(heading) %>%
summarise(twosd = sd())
View(workingdatatimecourseUnsmooth)
workingdatatimecourseUnsmooth %>%
group_by(ppid_trialn, heading) %>%
summarise(twosd = sd(mean(PeakMagnitude)))
workingdatatimecourseUnsmooth %>%
filter(heading == 2) %>%
group_by(ppid_trialn) %>%
summarise(standard = sd(mean(PeakMagnitude)))
workingdatathresholdUnsmooth %>%
filter(heading == 2) %>%
group_by(ppid_trialn) %>%
summarise(standard = sd(mean(PeakMagnitude)))
rm(list = ls())
# chooseCRANmirror(graphics=FALSE, ind=1) # uncomment for knitting
# rm(list = ls()) # clear workspace
knitr::opts_chunk$set(echo = TRUE)
install.packages(ggplot2)
install.packages(dplyr)
install.packages(tidyr)
install.packages(TTR)
install.packages(zoo)
# install.packages(matlabr)
# install.packages("magrittr")
setwd("M:/PhD/Project/Experiment_Code/Straights") # set working directory
# setwd("C:/Users/Courtney/Documents/PhD/Project/Experiment_code/Straights")
temp = list.files(pattern = c("BenLui17", "*.csv")) # list all CSV files in the directory
myfiles = lapply(temp, read.csv) # read these CSV in the directory
workingdata <- do.call(rbind.data.frame, myfiles) # convert and combine the CSV files into dataframe
library(dplyr)
library(tidyr)
library(TTR)
library(hemm)
library(searcher)
init_hemm()
# change in steering
magnitudethreshold = 0.140
upperthreshold = 0.105 # 0.2184 # upper threshold for consistent steering response
lowerthreshold = 0.005 # lower threshold for when response initiated - lowest of the IQRs for each mean YawRateChange condition
workingdata <- unite(workingdata, ppid_trialn, ppid, trialn, sep = "_") # create unique ppid_trialn ID
workingdata <- workingdata %>%
mutate(YawRateChange = YawRate_seconds - c(0, YawRate_seconds[-length(YawRate_seconds)])) %>% #difference in yaw rate
group_by(ppid_trialn) %>%
mutate(frame = row_number()) %>%
ungroup()
workingdata$YawRateChange[workingdata$YawRateChange >= 0.73499999] <- 0 # removes random spikes
colnames(workingdata)[colnames(workingdata)=="SWA"] <- "SWV"
workingdata <- workingdata %>%
mutate(SWA = SWV * 90)
# rows <- workingdata %>%
#   group_by(ppid_trialn) %>%
#   summarise(rows = n())
#
# View(rows)
library(dplyr)
workingdatatimecourseUnsmooth <- workingdata %>%
group_by(ppid_trialn) %>%
mutate(anchored_timestamp = timestamp - min(timestamp)) %>%
filter(anchored_timestamp<=min(anchored_timestamp)+4) %>%
ungroup() # create anchored timestamp and then only select first 4 seconds of data for each each ppid_trialn (only interested in the first steering adjustment as this point)
library(zoo)
library(dplyr)
library(tidyr)
library(TTR)
# implement anchored_timestamp again in code below to search only in first 1.5 seconds. Then use code above to calculate max peak thresholds and whether they pass the filter
# TRUERESPONSE <- workingdatatimecourseUnsmooth %>%
#   group_by(ppid_trialn) %>%
#   mutate(maxValue = max(abs(YawRateChange))) %>%
#   filter(maxValue >= 0.15) %>%
#   mutate(GenuineResponse = TRUE)
#
# FALSERESPONSE <- workingdatatimecourseUnsmooth %>%
#   group_by(ppid_trialn) %>%
#   mutate(maxValue = max(abs(YawRateChange))) %>%
#   filter(maxValue < 0.15) %>%
#   mutate(GenuineResponse = FALSE)
#
# workingdatatimecourseUnsmooth <- rbind(TRUERESPONSE, FALSERESPONSE)
workingdatatimecourseUnsmooth <- workingdatatimecourseUnsmooth %>%
group_by(ppid_trialn) %>%
mutate(PeakMagnitude = max(abs(YawRateChange))) %>% # calculate peak yaw rate change for each trial
ungroup()
workingdatathresholdUnsmooth <- workingdatatimecourseUnsmooth %>%
group_by(ppid_trialn) %>%
mutate(row_number(), Genuine_Response = if_else(PeakMagnitude >= magnitudethreshold, TRUE, FALSE)) %>%
filter(max(abs(YawRateChange)) > upperthreshold, min(abs(YawRateChange)) < lowerthreshold) %>% # filter lowest yaw rate change smaller than the lower theshold, # filter largest yaw rate change greater than the upper threshold
slice(1:min(which(abs(YawRateChange) > upperthreshold, 1))) %>%
slice(max(which(abs(YawRateChange) < lowerthreshold, 1))) %>% # which() returns rows where a condition is true. Taking the min() of all the rows that are greater than the criteria will return the first row where that is true.
ungroup() %>%
transmute(ppid_trialn, heading, cameraoffset, SWAThres = SWA, FirstSteeringTime = anchored_timestamp, ThresWorld_x = World_x, ThresWorld_z = World_z, ThresWorldYaw = WorldYaw, ThresYawRate_seconds = YawRate_seconds, ThresYawRateChange = YawRateChange, Genuine_Response = Genuine_Response, PeakMagnitude = PeakMagnitude) #, maxValue = maxValue, GenuineResponse = GenuineResponse)
workingdatathresholdUnsmooth <- workingdatathresholdUnsmooth %>%
group_by(heading) %>%
mutate(LateResponse = abs(FirstSteeringTime - mean(FirstSteeringTime)) > sd(FirstSteeringTime) & abs(FirstSteeringTime - mean(FirstSteeringTime)) > -sd(FirstSteeringTime))
# returns TRUE if response is more than 1 SD above or below mean first steering time
# guards against too fast/low responses
# returns TRUE if response is more than 1 SD from zero -> mutate(ResponseTooLate = if_else(FirstSteeringTime > 2*sd(FirstSteeringTime), TRUE, FALSE)) # label late responses
##################################### SMOOTHING DATA ###################################
workingdatatimecourseSmooth <- workingdatatimecourseUnsmooth %>%
mutate(smoothedYawRateChange = SMA(YawRateChange, n = 3)) # calculates moving average over the number of data points you specify
workingdatatimecourseSmooth[is.na(workingdatatimecourseSmooth)] <- 0 # set NA values to 0. This is because smoothing data in this way creates NA values if you don't have enough to average over. Unsure how else to get around this
# determine first time in each ppid, trialn group above threshold
workingdatathresholdSmooth <- workingdatatimecourseSmooth %>%
group_by(ppid_trialn) %>%
mutate(row_number(), Genuine_Response = if_else(PeakMagnitude >= magnitudethreshold, TRUE, FALSE)) %>%
filter(max(abs(smoothedYawRateChange)) > upperthreshold, # filter largest yaw rate change greater than the upper threshold
min(abs(smoothedYawRateChange)) < lowerthreshold) %>% # filter lowest yaw rate change smaller than the lower theshold
slice(1:min(which(abs(smoothedYawRateChange) > upperthreshold, 1))) %>%
slice(max(which(abs(smoothedYawRateChange) < lowerthreshold, 1))) %>% # which() returns rows where a condition is true. Taking the min() of all the rows that are greater than the criteria will return the first row where that is true.
ungroup() %>%
transmute(ppid_trialn, heading, cameraoffset, SWAThres = SWA, FirstSteeringTime = anchored_timestamp, ThresWorld_x = World_x, ThresWorld_z = World_z, ThresWorldYaw = WorldYaw, ThresYawRate_seconds = YawRate_seconds, ThresYawRateChange = smoothedYawRateChange, Genuine_Response = Genuine_Response, PeakMagnitude = PeakMagnitude)
workingdatathresholdSmooth <- workingdatathresholdSmooth %>%
group_by(heading) %>%
mutate(LateResponse = abs(FirstSteeringTime - mean(FirstSteeringTime)) > sd(FirstSteeringTime) & abs(FirstSteeringTime - mean(FirstSteeringTime)) > - sd(FirstSteeringTime))
# returns TRUE if response is more than 1 SD above or below mean first steering time
# guards against too fast/low responses
# returns TRUE if response is more than 1 SD from zero -> mutate(ResponseTooLate = if_else(FirstSteeringTime > 2*sd(FirstSteeringTime), TRUE, FALSE)) # label late responses
##################################### SMOOTHING DATA ###################################
# Here SWA angle is redundent as it only takes the SWA for when the change in yaw rate is over the threshold... I'm interested in ThresYawRateChange (first change in yaw rate over threhsold) and FirstYawRateChangeTimeThres (first timestamp where yaw rate change is over threshold).
#Only thing extra would be to calculate frame rate (60 frames) (ask Richard), and then multiply by change in yaw rate to get yaw rate per second per second.
install.packages("skimr")
View(workingdatathresholdSmooth)
ggplot(workingdatathresholdSmooth, aes(x = FirstSteeringTime)) +
geom_histogram()
ggplot(workingdatathresholdSmooth, aes(x = FirstSteeringTime)) +
geom_histogram() +
facet_wrap(~ heading)
headingtwo <- workingdatathresholdSmooth %>%
filter(heading == 2)
View(headingtwo)
shapiro.test(headingtwo$FirstSteeringTime)
install.packages("car")
headingtwo <- headingtwo$FirstSteeringTime
View(FirstSteeringTime)
View(headingtwo)
headingone <- workingdatathresholdSmooth %>%
filter(heading == 1)
headingone <- headingone$FirstSteeringTime
headingzero <- workingdatathresholdSmooth %>%
filter(heading == 0)
workingdatathresholdSmooth$heading <- as_factor(workingdatathresholdSmooth$heading)
workingdatathresholdSmooth$heading <- as.factor(workingdatathresholdSmooth$heading)
levenetest(0 ~ heading, data = workingdatathresholdSmooth)
library(car)
levenetest(0 ~ heading, data = workingdatathresholdSmooth)
leveneTest(0 ~ heading, data = workingdatathresholdSmooth)
install.packages("haven")
knitr::opts_chunk$set(echo = TRUE)
data<-read_spss("Iwasaki_Personality_Data.sav")
knitr::opts_chunk$set(echo = TRUE)
require(haven)
data<-read_spss("Iwasaki_Personality_Data.sav")
knitr::opts_chunk$set(echo = TRUE)
require(haven)
setwd("M:/PhD/Project/Experiment_Code/Straights")
data<-read_spss("Iwasaki_Personality_Data.sav")
View(data)
rm(list = ls())
# chooseCRANmirror(graphics=FALSE, ind=1) # uncomment for knitting
# rm(list = ls()) # clear workspace
knitr::opts_chunk$set(echo = TRUE)
install.packages(ggplot2)
install.packages(dplyr)
install.packages(tidyr)
install.packages(TTR)
install.packages(zoo)
install.packages(skimr)
install.packages(car)
# install.packages(matlabr)
# install.packages("magrittr")
setwd("M:/PhD/Project/Experiment_Code/Straights") # set working directory
# setwd("C:/Users/Courtney/Documents/PhD/Project/Experiment_code/Straights")
temp = list.files(pattern = c("BenLui17", "*.csv")) # list all CSV files in the directory
myfiles = lapply(temp, read.csv) # read these CSV in the directory
workingdata <- do.call(rbind.data.frame, myfiles) # convert and combine the CSV files into dataframe
library(dplyr)
library(tidyr)
library(TTR)
library(hemm)
library(searcher)
library(skimr)
init_hemm()
# change in steering
magnitudethreshold = 0.140
upperthreshold = 0.105 # 0.2184 # upper threshold for consistent steering response
lowerthreshold = 0.005 # lower threshold for when response initiated - lowest of the IQRs for each mean YawRateChange condition
workingdata <- unite(workingdata, ppid_trialn, ppid, trialn, sep = "_") # create unique ppid_trialn ID
workingdata <- workingdata %>%
mutate(YawRateChange = YawRate_seconds - c(0, YawRate_seconds[-length(YawRate_seconds)])) %>% #difference in yaw rate
group_by(ppid_trialn) %>%
mutate(frame = row_number()) %>%
ungroup()
workingdata$YawRateChange[workingdata$YawRateChange >= 0.73499999] <- 0 # removes random spikes
colnames(workingdata)[colnames(workingdata)=="SWA"] <- "SWV"
workingdata <- workingdata %>%
mutate(SWA = SWV * 90)
# rows <- workingdata %>%
#   group_by(ppid_trialn) %>%
#   summarise(rows = n())
#
# View(rows)
library(dplyr)
workingdatatimecourseUnsmooth <- workingdata %>%
group_by(ppid_trialn) %>%
mutate(anchored_timestamp = timestamp - min(timestamp)) %>%
filter(anchored_timestamp<=min(anchored_timestamp)+4) %>%
ungroup() # create anchored timestamp and then only select first 4 seconds of data for each each ppid_trialn (only interested in the first steering adjustment as this point)
library(zoo)
library(dplyr)
library(tidyr)
library(TTR)
# implement anchored_timestamp again in code below to search only in first 1.5 seconds. Then use code above to calculate max peak thresholds and whether they pass the filter
# TRUERESPONSE <- workingdatatimecourseUnsmooth %>%
#   group_by(ppid_trialn) %>%
#   mutate(maxValue = max(abs(YawRateChange))) %>%
#   filter(maxValue >= 0.15) %>%
#   mutate(GenuineResponse = TRUE)
#
# FALSERESPONSE <- workingdatatimecourseUnsmooth %>%
#   group_by(ppid_trialn) %>%
#   mutate(maxValue = max(abs(YawRateChange))) %>%
#   filter(maxValue < 0.15) %>%
#   mutate(GenuineResponse = FALSE)
#
# workingdatatimecourseUnsmooth <- rbind(TRUERESPONSE, FALSERESPONSE)
workingdatatimecourseUnsmooth <- workingdatatimecourseUnsmooth %>%
group_by(ppid_trialn) %>%
mutate(PeakMagnitude = max(abs(YawRateChange))) %>% # calculate peak yaw rate change for each trial
ungroup()
workingdatathresholdUnsmooth <- workingdatatimecourseUnsmooth %>%
group_by(ppid_trialn) %>%
mutate(row_number(), Genuine_Response = if_else(PeakMagnitude >= magnitudethreshold, TRUE, FALSE)) %>%
filter(max(abs(YawRateChange)) > upperthreshold, min(abs(YawRateChange)) < lowerthreshold) %>% # filter lowest yaw rate change smaller than the lower theshold, # filter largest yaw rate change greater than the upper threshold
slice(1:min(which(abs(YawRateChange) > upperthreshold, 1))) %>%
slice(max(which(abs(YawRateChange) < lowerthreshold, 1))) %>% # which() returns rows where a condition is true. Taking the min() of all the rows that are greater than the criteria will return the first row where that is true.
ungroup() %>%
transmute(ppid_trialn, heading, cameraoffset, SWAThres = SWA, FirstSteeringTime = anchored_timestamp, ThresWorld_x = World_x, ThresWorld_z = World_z, ThresWorldYaw = WorldYaw, ThresYawRate_seconds = YawRate_seconds, ThresYawRateChange = YawRateChange, Genuine_Response = Genuine_Response, PeakMagnitude = PeakMagnitude) #, maxValue = maxValue, GenuineResponse = GenuineResponse)
workingdatathresholdUnsmooth <- workingdatathresholdUnsmooth %>%
group_by(heading) %>%
mutate(LateResponse = abs(FirstSteeringTime - mean(FirstSteeringTime)) > sd(FirstSteeringTime) & abs(FirstSteeringTime - mean(FirstSteeringTime)) > -sd(FirstSteeringTime))
# returns TRUE if response is more than 1 SD above or below mean first steering time
# guards against too fast/low responses
# returns TRUE if response is more than 1 SD from zero -> mutate(ResponseTooLate = if_else(FirstSteeringTime > 2*sd(FirstSteeringTime), TRUE, FALSE)) # label late responses
##################################### SMOOTHING DATA ###################################
workingdatatimecourseSmooth <- workingdatatimecourseUnsmooth %>%
mutate(smoothedYawRateChange = SMA(YawRateChange, n = 3)) # calculates moving average over the number of data points you specify
workingdatatimecourseSmooth[is.na(workingdatatimecourseSmooth)] <- 0 # set NA values to 0. This is because smoothing data in this way creates NA values if you don't have enough to average over. Unsure how else to get around this
# determine first time in each ppid, trialn group above threshold
workingdatathresholdSmooth <- workingdatatimecourseSmooth %>%
group_by(ppid_trialn) %>%
mutate(row_number(), Genuine_Response = if_else(PeakMagnitude >= magnitudethreshold, TRUE, FALSE)) %>%
filter(max(abs(smoothedYawRateChange)) > upperthreshold, # filter largest yaw rate change greater than the upper threshold
min(abs(smoothedYawRateChange)) < lowerthreshold) %>% # filter lowest yaw rate change smaller than the lower theshold
slice(1:min(which(abs(smoothedYawRateChange) > upperthreshold, 1))) %>%
slice(max(which(abs(smoothedYawRateChange) < lowerthreshold, 1))) %>% # which() returns rows where a condition is true. Taking the min() of all the rows that are greater than the criteria will return the first row where that is true.
ungroup() %>%
transmute(ppid_trialn, heading, cameraoffset, SWAThres = SWA, FirstSteeringTime = anchored_timestamp, ThresWorld_x = World_x, ThresWorld_z = World_z, ThresWorldYaw = WorldYaw, ThresYawRate_seconds = YawRate_seconds, ThresYawRateChange = smoothedYawRateChange, Genuine_Response = Genuine_Response, PeakMagnitude = PeakMagnitude)
workingdatathresholdSmooth <- workingdatathresholdSmooth %>%
group_by(heading) %>%
mutate(LateResponse = abs(FirstSteeringTime - mean(FirstSteeringTime)) > sd(FirstSteeringTime) & abs(FirstSteeringTime - mean(FirstSteeringTime)) > - sd(FirstSteeringTime))
# returns TRUE if response is more than 1 SD above or below mean first steering time
# guards against too fast/low responses
# returns TRUE if response is more than 1 SD from zero -> mutate(ResponseTooLate = if_else(FirstSteeringTime > 2*sd(FirstSteeringTime), TRUE, FALSE)) # label late responses
##################################### SMOOTHING DATA ###################################
# Here SWA angle is redundent as it only takes the SWA for when the change in yaw rate is over the threshold... I'm interested in ThresYawRateChange (first change in yaw rate over threhsold) and FirstYawRateChangeTimeThres (first timestamp where yaw rate change is over threshold).
#Only thing extra would be to calculate frame rate (60 frames) (ask Richard), and then multiply by change in yaw rate to get yaw rate per second per second.
workingdatathresholdSmooth$heading2 <- workingdatathresholdSmooth %>%
filter(heading == 2)
workingdatathresholdSmooth_heading2 <- workingdatathresholdSmooth %>%
filter(heading == 2)
shapiro.test(workingdatathresholdSmooth_heading2)
shapiro.test(workingdatathresholdSmooth_heading2$FirstSteeringTime)
workingdatathresholdSmooth$heading_fact <- as.factor(workingdatathresholdSmooth$heading)
View(workingdatathresholdSmooth)
leveneTest(0 ~ heading_fact, data = workingdatathresholdSmooth)
leveneTest(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
Anova1<-aov(FirstSteering ~ heading_fact, data = workingdatathresholdSmooth)
summary(Anova1)
Anova1<-aov(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
summary(Anova1)
library(dplyr)
workingdatathresholdUnsmooth %>%
group_by(heading) %>%
summarise(meanFirstSteeringTime = mean(FirstSteeringTime, na.rm = TRUE))
workingdatathresholdUnsmooth %>%
filter(Genuine_Response == TRUE & LateResponse == FALSE) %>%
group_by(heading) %>%
summarise(meanFirstSteeringTimeTRUE = mean(FirstSteeringTime, na.rm = TRUE))
workingdatathresholdSmooth %>%
group_by(heading) %>%
summarise(meanFirstSteeringTimeALLRESPONSES = mean(FirstSteeringTime, na.rm = TRUE))
workingdatathresholdSmooth %>%
filter(Genuine_Response == TRUE & LateResponse == FALSE) %>%
group_by(heading) %>%
summarise(meanFirstSteeringTimeGENUINERESPONSES = mean(FirstSteeringTime, na.rm = TRUE))
Anova1 <- aov(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
summary(Anova1)
install.packages("ez")
# chooseCRANmirror(graphics=FALSE, ind=1) # uncomment for knitting
# rm(list = ls()) # clear workspace
knitr::opts_chunk$set(echo = TRUE)
install.packages(ggplot2)
install.packages(dplyr)
install.packages(tidyr)
install.packages(TTR)
install.packages(zoo)
install.packages(skimr)
install.packages(car)
install.packages(ez)
# install.packages(matlabr)
# install.packages("magrittr")
setwd("M:/PhD/Project/Experiment_Code/Straights") # set working directory
# setwd("C:/Users/Courtney/Documents/PhD/Project/Experiment_code/Straights")
temp = list.files(pattern = c("BenLui17", "*.csv")) # list all CSV files in the directory
myfiles = lapply(temp, read.csv) # read these CSV in the directory
workingdata <- do.call(rbind.data.frame, myfiles) # convert and combine the CSV files into dataframe
library(ez)
View(data())
View(data)
knitr::opts_chunk$set(echo = TRUE)
require(haven)
setwd("M:/PhD/Project/Experiment_Code/Straights")
dataexample <- read_spss("Iwasaki_Personality_Data.sav")
View(dataexample)
Ez_ANOVA1 <- ezANOVA(workingdatathresholdSmooth, dv = FirstSteeringTime, wid = ppid_trialn, between = heading_fact, detailed = TRUE)
Ez_ANOVA1
Ez_ANOVA1 <- ezANOVA(workingdatathresholdSmooth, dv = FirstSteeringTime, wid = heading, between = heading_fact, detailed = TRUE)
Ez_ANOVA1 <- ezANOVA(workingdatathresholdSmooth, dv = FirstSteeringTime, between = heading_fact, detailed = TRUE)
install.packages("apaTables")
# chooseCRANmirror(graphics=FALSE, ind=1) # uncomment for knitting
# rm(list = ls()) # clear workspace
knitr::opts_chunk$set(echo = TRUE)
install.packages(ggplot2) # for plots
install.packages(dplyr) # for manipulating data frames
install.packages(tidyr) # for tidying data (uniting columns)
install.packages(TTR) # for smoothing data with mean of observations
install.packages(zoo)
install.packages(skimr)
install.packages(car) # to perform levenes and anova
install.packages(apaTables) # to create apa table
# install.packages(matlabr)
# install.packages("magrittr")
setwd("M:/PhD/Project/Experiment_Code/Straights") # set working directory
# setwd("C:/Users/Courtney/Documents/PhD/Project/Experiment_code/Straights")
temp = list.files(pattern = c("BenLui17", "*.csv")) # list all CSV files in the directory
myfiles = lapply(temp, read.csv) # read these CSV in the directory
workingdata <- do.call(rbind.data.frame, myfiles) # convert and combine the CSV files into dataframe
library(ggplot2)
library(dplyr)
library(car)
library(apaTables)
# Anova
Anova1 <- aov(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
summary(Anova1)
apa.aov.table(Anova1, filename = "APA_Anova_Table.doc", table.number = 1)
install.packages("MBESS")
library(MBESS)
# Anova
Anova1 <- aov(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
summary(Anova1)
apa.aov.table(Anova1, filename = "APA_Anova_Table.doc", table.number = 1)
resultTukey<-TukeyHSD(Anova1)
resultTukey
install.packages("WRS2")
# chooseCRANmirror(graphics=FALSE, ind=1) # uncomment for knitting
# rm(list = ls()) # clear workspace
knitr::opts_chunk$set(echo = TRUE)
install.packages(ggplot2) # for plots
install.packages(dplyr) # for manipulating data frames
install.packages(tidyr) # for tidying data (uniting columns)
install.packages(TTR) # for smoothing data with mean of observations
install.packages(zoo)
install.packages(skimr)
install.packages(car) # to perform levenes and anova
install.packages(apaTables) # to create apa table
install.packages(WRS2) # for non-parametric anova
# install.packages(matlabr)
# install.packages("magrittr")
setwd("M:/PhD/Project/Experiment_Code/Straights") # set working directory
# setwd("C:/Users/Courtney/Documents/PhD/Project/Experiment_code/Straights")
temp = list.files(pattern = c("BenLui17", "*.csv")) # list all CSV files in the directory
myfiles = lapply(temp, read.csv) # read these CSV in the directory
workingdata <- do.call(rbind.data.frame, myfiles) # convert and combine the CSV files into dataframe
library(WRS2) # for non-parametric
Nonpara_Anova1 <- t1way(FirstSteeringTiME ~ heading_fact, data = workingdatathresholdSmooth)
Nonpara_Anova1 <- t1way(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
summary(Nonpara_Anova1)
t1way(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
t1way(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
t1waybt(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth, nboot = 10000)
Nonpara_Anova <- t1way(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
lincoln(Nonpara_Anova)
Nonpara_Anova <- t1way(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
resultslincoln <- lincoln(Nonpara_Anova)
library(WRS2) # for non-parametric
Nonpara_Anova <- t1way(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
lincoln(Nonpara_Anova)
Nonpara_Anova <- t1way(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
lincon(Nonpara_Anova)
Nonpara_Anova <- t1way(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
lincon(Nonpara_Anova)
Nonpara_Anova <- t1way(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
lincon(FirstSteeringTime ~ heading_fact, data = workingdatathresholdSmooth)
