---
title: "accumulation_code"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r data and package loading}

setwd("C:/Users/Courtney/Documents/PhD/Project/Experiment_code/Straights")
temp = list.files(pattern = c("dat_example")) # list all CSV files in the directory
myfiles = lapply(temp, read.csv) # read these CSV in the directory
dat <- do.call(rbind.data.frame, myfiles) 

```


```{r RWIener with real experimental data - computing condition dataframes}
library(RWiener)
# View(dat) # dataframe containing all trials (upper = correct trials, lower = incorrect trials)

dat$heading <- as.character(dat$heading) # converting to character before converting to numeric for filtering
dat$heading <- as.numeric(dat$heading)

dat <- dat %>%
  dplyr::filter(heading > 0) # filter out zero headings for modelling

# seperate conditions into different dataframes 

# 0.5 heading
dat0_5 <- dat %>%
  dplyr::filter(heading == 0.5)
dat0_5 <- data.frame(q = dat0_5$FirstSteeringTime, resp = dat0_5$resp)
wiener_plot(dat0_5)

# 1.0 heading
dat1_0 <- dat %>%
  dplyr::filter(heading == 1.0)
dat1_0 <- data.frame(q = dat1_0$FirstSteeringTime, resp = dat1_0$resp)
wiener_plot(dat1_0)

# 1.5 heading
dat1_5 <- dat %>%
  dplyr::filter(heading == 1.5)
dat1_5 <- data.frame(q = dat1_5$FirstSteeringTime, resp = dat1_5$resp)
wiener_plot(dat1_5)

# 2.0 heading
dat2_0 <- dat %>%
  dplyr::filter(heading == 2.0)
dat2_0 <- data.frame(q = dat2_0$FirstSteeringTime, resp = dat2_0$resp)
wiener_plot(dat2_0)


```

```{r estimating parameters for one condition}

# using optim, first with Nelder-Mead algorithm, then with BFGS
optim1 <- optim(c(1, .1, .1, 1), wiener_deviance, dat = dat2_0, method = "Nelder-Mead")
optim2 <- optim(optim1[["par"]], wiener_deviance, dat = dat2_0, method = "BFGS", hessian = TRUE)


# using nlm, which uses a Newton-type algorithm
nlm1 <- nlm(p = c(1, .1, .1, 1), f = wiener_deviance, dat = dat2_0)

# creates estimates for parameters for that condition. They can be used to produce further inferences or create predicitions for other values. Estimate values occur in this order:
# [alpha (seperation between the boundaries), non-decision time, initial bias, drift rate]


# currently optim() and nlm() give negative drift rates for some conditions...

```

Above code attempts to compute parameter values (seperation boundaries, non-decision time, initial bias and drift rate).

Algorithm inputs parameter values to see which explain the distribution of the data the best, and the best fitting value parameters get selected. It does this for each condition dataframe that is inputted. The following results are generated:


**0.5 heading**

alpha (boundary seperation) = 4.46
non-decision time = 0.19
initial bias = 0.88
drift rate = -1.35

**1.0 heading**

alpha (boundary seperation) = 3.17
non-decision time = 0.14
initial bias = 0.81
drift rate = -0.44

**1.5 heading**

alpha (boundary seperation) = 2.66
non-decision time = 0.13
initial bias = 0.76
drift rate = 0.09

**2.0 heading**

alpha (boundary seperation) = 2.57
non-decision time = 0.13
initial bias = 0.76
drift rate = 0.21

Despite forcing the code to work, the results from analysing the individual conditions makes intuitive sense. As heading offset angle increases, the drift rate increases. This is what we would expect from an evidence accumulation model interpretation of RT distributions. 


```{r estimating parameters with multiple conditions}
# deviance function for multiple conditions

many_drifts <- function(x, datlist) {
l = 0
for (c in 1:length(datlist)) {
l = l + wiener_deviance(x[c(1, 2, 3, c+3)], datlist[[c]])
}
return(l)
}

# put multiple dataframe conditions into one dataframe list

datlist <- list(dat0_5, dat1_0, dat1_5, dat2_0)

# use nlm to estimate parameters

nlm2 <- nlm(p=c(1, .1, .1, 1, 1, 1, 1), f=many_drifts, dat=datlist)

# add 2 extra 1's empty vector and the code MIGHT work... ^





```


