---
title: "modelling individual participants"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load data}
# rm(list = ls())

setwd("C:/Users/pscmgo/OneDrive for Business/PhD/Project/Experiment_Code/Straights")
temp = list.files(pattern = c("magnitudedata", "*.csv")) # list all CSV files in the directory
myfiles = lapply(temp, read.csv) # read these CSV in the directory
magnitudedata <- do.call(rbind.data.frame, myfiles) # convert and combine the CSV files into dataframe

```

```{r load packages}

library(ggplot2)
library(dplyr)
library(car)
library(MASS)
library(dplyr)
library(EnvStats)
library(lme4)
library(nlme)
library(tidyr)

```

```{r median RT per participant}


magnitudedata <- magnitudedata %>%
  dplyr::filter(heading > 0) # filter out zero headings 

ggplot(magnitudedata %>%
         group_by(pNum, heading) %>%
         summarise(medianRT = median(FirstSteeringTime)), aes(x = heading, y = medianRT)) +
  geom_point() +
  geom_line() +
  facet_wrap(~ pNum)



```

Median RTs across heading seem to be fairly consistent across subjects

```{r fitting of multilevel model using lmer function without gaussian link function}

modellingdata <- magnitudedata %>%
  dplyr::filter(heading > 0) %>% # remove 0 heading trials for modelling data
  mutate(inver_heading = 1 / heading) # compute inverse of heading for ease of interpretting intercept

# model 1 - varying intercept
m1 <- lmer(formula = FirstSteeringTime ~ inver_heading + (1 | pNum), data = modellingdata)
summary(m1)
# coef(m1)


# model 2 -  varying intercept and slope
m2 <- lmer(formula = FirstSteeringTime ~ inver_heading + (1 + inver_heading | pNum), data = modellingdata)
summary(m2)
# coef(m2)


# model 3 -  varying intercept and slope
# m3 <- lmer(formula = FirstSteeringTime ~ inver_heading + (1 + heading | pNum), data = modellingdata)
# summary(m2)
# # coef(m2)




par(mfrow=c(2,2))
plot(fitted(m2),resid(m2,type="pearson"),col="blue") # a plot to check the constant standard deviation
abline(h=0,lwd=2)

qqnorm(resid(m2)) # normality of the residuals
qqline(resid(m2))

qqnorm(ranef(m2)$pNum[,1])
qqline(ranef(m2)$pNum[,1])

plot(coef(m2)$pNum)


```
m1 model formula specifies how FirstSteeringTime is explained by heading. The 1 specifies a varying intercept to vary by participant. coef(m1) shows the different intercepts for each participant. 

m2 model forumula specifies how FirstSteeringTime is explained by heading, except (1 + heading | pNum) allows intercept and slope to vary between participants. Essentially, both the intercept and the slope of heading will vary by pNum, thus accounting for subject variability in baseline fastest RTs and the subject variability in the sensitivity to heading conditions. 

coef(m2) shows the different intercepts for each participant. This mixed model approach allows for estimating of the overall mean response for the explanatory variables whilst adding random deviation based upon the grouping structure i.e. the subjects.

**Residual plot versus fitted values**
This plot possibly shows dependency between fitted and and residual values. Could this indicate that a varying intercept, varying slope model might not be the best. This type of model assumes a normal distribution, however dependency in the plot suggests that this is not the case for the data. 


**Residual Q-Q plot**
This plot visualises the normality of the residuals. Ideally the points should fall on the line for "normality". Most of the points do, however the tails deviate away from the line indicating slight non-normality of the data...

**Conditional modes Q-Q plot**
This plot computers the difference between the (population-level) average predicted response for a given set of fixed-effect values (i.e. heading offset angle) and the response predicted for a particular individual. These can be thought of as individual-level effects, i.e. how much does any individual differ from the population? 

**Coeffiecient plot**
This plots plots coefficients against the intercept, thus visualising the random effects correlation between the intercept and the slope. This visualises the negative correlation (-.39), demonstrating that individuals intercept variation has an effect on the heading slope variation.


```{r saving average intercepts and slopes}
# model 1
AvgInterceptm1 <- summary(m1)$coef[1,1]
AvgSlopem1 <- summary(m1)$coef[2,1]

# model 2
AvgInterceptm2 <- summary(m2)$coef[1,1]
AvgSlopem2 <- summary(m2)$coef[2,1]

```


```{r visualising intercepts and slopes for each participant}

interceptsm1 <- coef(m1)$pNum[,1] # Specifying the first column only
slopesm1 <- coef(m1)$pNum[,2] # Specifying the second column only

# varying intercept (slope is fixed)
ggplot(modellingdata, aes(x = inver_heading, y = FirstSteeringTime, color = as.factor(pNum))) + 
  geom_jitter(alpha = .3) +
  geom_abline(slope = slopesm1, intercept = interceptsm1) +
  # geom_abline(slope = AvgSlopem1, intercept = AvgInterceptm1, color = "red", size = 1, show.legend = TRUE) +
  theme(legend.position = "none") +
  theme(axis.text.x = element_blank()) +
  ggtitle("RTs against heading - varying intercept only (model 1)")


interceptsm2 <- coef(m2)$pNum[,1] # Specifying the first column only
slopesm2 <- coef(m2)$pNum[,2] # Specifying the second column only

# varying intercept and slope
ggplot(modellingdata, aes(x = inver_heading, y = FirstSteeringTime, color = as.factor(pNum))) + 
  geom_jitter(alpha = .3) +
  geom_abline(slope = slopesm2, intercept = interceptsm2) +
  # geom_abline(slope = AvgSlopem2, intercept = AvgInterceptm2, color = "red", size = 1, show.legend = TRUE) +
  theme(legend.position = "none") +
  theme(axis.text.x = element_blank()) +
  ggtitle("RTs against heading - varying slope and intercept (model 2)")
  
  
# checking intercepts and slopes for individual subjects (unsure how facet_wrap subjectw with their individual intercepts and slopes...)

# ggplot(magnitudedata %>%
#          dplyr::filter(pNum == 7), aes(x = heading, y = FirstSteeringTime, color = as.factor(pNum))) + 
#   geom_jitter(alpha = .3) +
#   geom_abline(slope = slopesm2[7], intercept = interceptsm2[7], alpha = .5) +
#   geom_abline(slope = AvgSlopem2, intercept = AvgInterceptm2, color = "red", size = 1, show.legend = TRUE) +
#   theme(legend.position = "none") +
#   ggtitle("RTs against heading - varying slope and intercept for an individual")

```
For both plots, heading is inverted. This means 2 degrees of heading offset angle is furtherest to the left. This improves interpretation of the intercept, which should be where subejcts are reacting as quickly as possible.

Varying intercept relates to baseline reaction time i.e. latency for how participants react as fast as they can (when error is instantly above threshold). As expected, this varies a lot between participants. In this case, intercept relates to as fast as possible reactions which will naturally vary amongst the population. 

Allowing the intercept and the slope to vary allows you to see if subjects differ in their sensitivity to heading. First plot proposes that variation in RT is based upon the individuals latency. When we allow the slopes to vary, intercepts become more similar however there is still some variation. There is a slight correlation between intercept and the slope in the random effects output which could suggest that variation in the intercept is affecting variation in heading slope (i.e. variation in subjects baseline fastest RTs affects the sensitivity to the heading condition).

```{r model comparions}

anova(m1, m2)

```
We can then compare the models by computing a chi squared test. They significantly differ from each other. Model 2 also has lower AIC value, suggesting that it is the best model in explaining the data (i.e. subject variation in sensitivity to the heading).

```{r histogram and density plots}

ggplot() + 
  geom_density(aes(x = slopesm1), col = "blue", show.legend = TRUE) +
  geom_density(aes(x = slopesm2), col = "red", show.legend = TRUE) +
  xlab("slope") +
  ggtitle("Slope density plots")
  

ggplot() + 
  geom_density(aes(x = interceptsm1), col = "blue", show.legend = TRUE) +
  geom_density(aes(x = interceptsm2), col = "red", show.legend = TRUE) +
  xlab("intercept") +
  ggtitle("Intercept density plots")

```
**Slope density pplots**

Blue indicates model 1, red line indicates model 2. Variance in the slopes between the two models is actually very similar according to the density plots.

**Intercept density plots**

Blue indicates model 1, red line indicates model 2. The variance is more spread for model 2 than for model 1. Does this indicate that when you allow the slope to vary according to the heading, variation between the participants increases. Thus subject variability has an affect on the sensitivity towards the heading conditions.

```{r simulating data for testing model fit (taken from Callum's code)}

pp_n <- 20  #number of participants
trials_n <- 160  #number of trials
sigma_y <- 1 # within-participant variability / measurement error

a       <-  0    # average control condition mean
b       <- .5    # average effect size
sigma_a <- 0.06479     # std dev in intercepts (control means, between participant variability)
sigma_b <-  0.07140   # std dev in slopes (effect size)
rho     <-  -0.39   # correlation between intercepts and slopes

#combine means and standard deviations for multivariate gaussian sampling
mu <- c(a, b)
sigmas <- c(sigma_a, sigma_b)          # standard deviations
rho    <- matrix(c(1, rho,             # correlation matrix
                   rho, 1), nrow = 2)

# now matrix multiply to get covariance matrix
sigma <- diag(sigmas) %*% rho %*% diag(sigmas)

#let's create our participant level parameters
set.seed(1)  # used to replicate example
vary_effects <- MASS::mvrnorm(pp_n, mu, sigma) #use multivariate gaussian

#rename columns for varying intercepts and varying slopes
vary_effects <- vary_effects %>% as_tibble() %>% rename(pp_a = V1,
                                                        pp_b = V2)

  
# now simulate observations.

# this piping operation is a little involved, but essential it makes a dataframe of with trial_n entries of all  combinations of participant intercepts and slopes. Then adds a binary column to signify whether the condition is the experimental (1) or control (0). It then uses this column to switch 'on' or 'off' the experimental effect to generate a column of participant condition means. Then it uses the specified (and  constant) within-individual variability (or measurement error) to generate observations

set.seed(1)  # used to replicate example
data <- vary_effects %>% 
  mutate(pp = 1:pp_n) %>% 
  tidyr::expand(nesting(pp, pp_a, pp_b), trial = 1:trials_n) %>% 
  mutate(condition = rep(0:1, times = n() / 2)) %>% 
  mutate(mu = pp_a + pp_b * condition) %>% 
  mutate(measurement = rnorm(n = n(), mean = mu, sd = sigma_y))

head(data)

#quick plot.
ggplot(data, aes(x=measurement, group=condition)) + geom_density()

# 
magnitudedata %>%
  group_by(pNum) %>%
  summarise(n = n()) %>%
  summarise(mean = mean(n))

```

```{r fitting multi-level model for simulated data}

m3 <- lmer(formula = measurement ~ condition + (1 + condition | pp), data = data)
summary(m3)

interceptsm3 <- coef(m3)$pp[,1] # Specifying the first column only
slopesm3 <- coef(m3)$pp[,2] # Specifying the second column only

ggplot(data, aes(x = condition, y = measurement, color = as.factor(pp))) +
  geom_jitter(alpha = .3, show.legend = FALSE) +
  geom_abline(slope = slopesm3, intercept = interceptsm3)

mean(slopesm2)
sd(slopesm2)
sd(interceptsm2)

mean(slopesm3)
sd(slopesm3)
sd(interceptsm3)

```
Model 3 is fitted from the simulated data based on model 2 that was fitted to actual data. 

**160 trials per participant (average number of trials per participant in real data)**
In comparison to model 2, model 3 has less individual variation. There is also less subject variation towards the sensitivity of the heading condition.

```{r more model simulations from Gelman & Hill book}
library(arm)

n.sims <- 1000
fit.1 <- lm(FirstSteeringTime ~ heading, data = magnitudedata)
sim.1 <- sim(fit.1, n.sims)

```
For classical linear and generalised linear models, sim function simulates different coefficients values and sigma values. Sigma value present estimation uncertainty in residual standard deviation.

```{r are simulations similar to regression computations}

heading.coef <- sim.1@coef[,2]
mean(heading.coef)
sd(heading.coef)
quantile(heading.coef, c(.025, .975))


```


```{r mixed model inference - simulations and 95% CIs}

# plot heading effects 

# Simulate new data based upon the fitted model
new_data <- data.frame(inver_heading = as.numeric(1 / seq(0.5,2,length = 4)))
pred_data <- predict(m2, newdata = new_temp, re.form = ~0)

# compute bootstrapped confidence interval, see ?predict.merMod
ci_line <- bootMer(m2, FUN = function(.) predict(.,newdata = new_temp, re.form = ~0), nsim = 200)
ci_regT <- apply(ci_line$t, 2, function(x) x[order(x)][c(5,195)])

# plot original data with CIs from simulated data
plot(FirstSteeringTime ~ jitter(inver_heading, 2), modellingdata)
lines(new_data$inver_heading, pred_data, lwd = 3)
lines(new_data$inver_heading, ci_regT[1,], lty = 2)
lines(new_data$inver_heading, ci_regT[2,], lty = 2)
mtext(text = "Regression curves with 95% confidence intervals", side = 3, outer = FALSE, at = -3)

```
This method of inference simulates new reaction time data from the given explanatory variables (inverse heading) and the fitted model. It then re-fits the model to these simulated response values and extracts the fitted coefficient. From the distribution of bootstrapped coefficients, it will draw a 95% confidence intervals (dashed lines) around the fitted values (solid lines).

The small range of the confidence intervals provides increased certainty that the fitted model for these data is valid and reliable. Calculating the confidence intervals from 200 simulations improves this further.

```{r individual regression lines for individual participants}

# create empty vectors for slope coefficients and intercepts
heading_coefs = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA)
heading_intercept = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA)

for (i in c(1:19)){
  # Create temporary data frame:
heading_tmp <- modellingdata[modellingdata$pNum == i,]
  # Perform regression:
reg_result <- lm(heading_tmp$FirstSteeringTime ~ heading_tmp$inver_heading)
  # Get coefficient:
tmp_coef <- coef(reg_result)

# Store coefficient and intercept for each subject:
heading_coefs[i] <- tmp_coef[2] 
heading_intercept[i] <- tmp_coef[1]

plot(jitter(heading_tmp$inver_heading, 3), heading_tmp$FirstSteeringTime)
abline(heading_intercept[i], heading_coefs[i])

}

# plotting individuals on the same plot
ggplot(modellingdata, aes(x = inver_heading, y = FirstSteeringTime, color = as.factor(pNum))) + 
  geom_jitter(alpha = .3) +
  geom_abline(slope = heading_coefs, intercept = heading_intercept) +
  theme(legend.position = "none") +
  theme(axis.text.x = element_blank()) +
  ggtitle("RTs against heading - individual single level regression slopes")


```
The above code computes a single level regression line for each participant. It them plots the regression line for each subject on their individual RT data points for inverse heading.

Ordinary regression assumes that different observations are independent, however this is often violated with a within-subjects design. However this assumption does not apply when extracting individual regression lines and thus this technique circumvents this. However, because the subject regressiona lines are not computed toegther, there is no measurment of the variance accounted within the model.
